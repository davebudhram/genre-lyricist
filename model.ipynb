{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/davebudhram/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "import csv\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "      <th>link</th>\n",
       "      <th>text</th>\n",
       "      <th>genre</th>\n",
       "      <th>generic_genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Ahe's My Kind Of Girl</td>\n",
       "      <td>/a/abba/ahes+my+kind+of+girl_20598417.html</td>\n",
       "      <td>Look at her face, it's a wonderful face  \\r\\nA...</td>\n",
       "      <td>['europop', 'swedish pop']</td>\n",
       "      <td>pop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Andante, Andante</td>\n",
       "      <td>/a/abba/andante+andante_20002708.html</td>\n",
       "      <td>Take it easy with me, please  \\r\\nTouch me gen...</td>\n",
       "      <td>['europop', 'swedish pop']</td>\n",
       "      <td>pop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>As Good As New</td>\n",
       "      <td>/a/abba/as+good+as+new_20003033.html</td>\n",
       "      <td>I'll never know why I had to go  \\r\\nWhy I had...</td>\n",
       "      <td>['europop', 'swedish pop']</td>\n",
       "      <td>pop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Bang</td>\n",
       "      <td>/a/abba/bang_20598415.html</td>\n",
       "      <td>Making somebody happy is a question of give an...</td>\n",
       "      <td>['europop', 'swedish pop']</td>\n",
       "      <td>pop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Bang-A-Boomerang</td>\n",
       "      <td>/a/abba/bang+a+boomerang_20002668.html</td>\n",
       "      <td>Making somebody happy is a question of give an...</td>\n",
       "      <td>['europop', 'swedish pop']</td>\n",
       "      <td>pop</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  artist                   song                                        link  \\\n",
       "0   ABBA  Ahe's My Kind Of Girl  /a/abba/ahes+my+kind+of+girl_20598417.html   \n",
       "1   ABBA       Andante, Andante       /a/abba/andante+andante_20002708.html   \n",
       "2   ABBA         As Good As New        /a/abba/as+good+as+new_20003033.html   \n",
       "3   ABBA                   Bang                  /a/abba/bang_20598415.html   \n",
       "4   ABBA       Bang-A-Boomerang      /a/abba/bang+a+boomerang_20002668.html   \n",
       "\n",
       "                                                text  \\\n",
       "0  Look at her face, it's a wonderful face  \\r\\nA...   \n",
       "1  Take it easy with me, please  \\r\\nTouch me gen...   \n",
       "2  I'll never know why I had to go  \\r\\nWhy I had...   \n",
       "3  Making somebody happy is a question of give an...   \n",
       "4  Making somebody happy is a question of give an...   \n",
       "\n",
       "                        genre generic_genre  \n",
       "0  ['europop', 'swedish pop']           pop  \n",
       "1  ['europop', 'swedish pop']           pop  \n",
       "2  ['europop', 'swedish pop']           pop  \n",
       "3  ['europop', 'swedish pop']           pop  \n",
       "4  ['europop', 'swedish pop']           pop  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('processed_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_GRAM = 4\n",
    "SENTENCE_BEGIN = \"<s>\"\n",
    "SENTENCE_END = \"</s>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_line(line: str, ngram: int, \n",
    "                   by_char: bool = True, \n",
    "                   space_char: str = ' ',\n",
    "                   sentence_begin: str=SENTENCE_BEGIN, \n",
    "                   sentence_end: str=SENTENCE_END):\n",
    "  \"\"\"\n",
    "  Tokenize a single string. Glue on the appropriate number of \n",
    "  sentence begin tokens and sentence end tokens (ngram - 1), except\n",
    "  for the case when ngram == 1, when there will be one sentence begin\n",
    "  and one sentence end token.\n",
    "  Args:\n",
    "    line (str): text to tokenize\n",
    "    ngram (int): ngram preparation number\n",
    "    by_char (bool): default value True, if True, tokenize by character, if\n",
    "      False, tokenize by whitespace\n",
    "    space_char (str): if by_char is True, use this character to separate to replace spaces\n",
    "    sentence_begin (str): sentence begin token value\n",
    "    sentence_end (str): sentence end token value\n",
    "\n",
    "  Returns:\n",
    "    list of strings - a single line tokenized\n",
    "  \"\"\"\n",
    "  # PROVIDED\n",
    "  inner_pieces = None\n",
    "  if by_char:\n",
    "    line = line.replace(' ', space_char)\n",
    "    inner_pieces = list(line)\n",
    "  else:\n",
    "    # otherwise use nltk's word tokenizer\n",
    "    inner_pieces = nltk.word_tokenize(line)\n",
    "\n",
    "  if ngram == 1:\n",
    "    tokens = [sentence_begin] + inner_pieces + [sentence_end]\n",
    "  else:\n",
    "    tokens = ([sentence_begin] * (ngram - 1)) + inner_pieces + ([sentence_end] * (ngram - 1))\n",
    "  # always count the unigrams\n",
    "  return tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_tokenize_line(line, genre, ngram=N_GRAM):\n",
    "  result = []\n",
    "  sentences = line.split('\\r\\n')\n",
    "  for sentence in sentences:\n",
    "    tokens = [SENTENCE_BEGIN] + nltk.word_tokenize(sentence) + [SENTENCE_END]\n",
    "    ngrams = (list(nltk.ngrams(tokens, ngram-1)))\n",
    "    for gram in ngrams:\n",
    "      ngram_as_list = [genre] + list(gram)\n",
    "      result.append(ngram_as_list)\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['pop', '<s>', 'Look', 'at'], ['pop', 'Look', 'at', 'her'], ['pop', 'at', 'her', 'face'], ['pop', 'her', 'face', ','], ['pop', 'face', ',', 'it'], ['pop', ',', 'it', \"'s\"], ['pop', 'it', \"'s\", 'a'], ['pop', \"'s\", 'a', 'wonderful'], ['pop', 'a', 'wonderful', 'face'], ['pop', 'wonderful', 'face', '</s>'], ['pop', '<s>', 'And', 'it'], ['pop', 'And', 'it', 'means'], ['pop', 'it', 'means', 'something'], ['pop', 'means', 'something', 'special'], ['pop', 'something', 'special', 'to'], ['pop', 'special', 'to', 'me'], ['pop', 'to', 'me', '</s>'], ['pop', '<s>', 'Look', 'at'], ['pop', 'Look', 'at', 'the'], ['pop', 'at', 'the', 'way'], ['pop', 'the', 'way', 'that'], ['pop', 'way', 'that', 'she'], ['pop', 'that', 'she', 'smiles'], ['pop', 'she', 'smiles', 'when'], ['pop', 'smiles', 'when', 'she'], ['pop', 'when', 'she', 'sees'], ['pop', 'she', 'sees', 'me'], ['pop', 'sees', 'me', '</s>'], ['pop', '<s>', 'How', 'lucky'], ['pop', 'How', 'lucky', 'can'], ['pop', 'lucky', 'can', 'one'], ['pop', 'can', 'one', 'fellow'], ['pop', 'one', 'fellow', 'be'], ['pop', 'fellow', 'be', '?'], ['pop', 'be', '?', '</s>'], ['pop', '<s>', 'She', \"'s\"], ['pop', 'She', \"'s\", 'just'], ['pop', \"'s\", 'just', 'my'], ['pop', 'just', 'my', 'kind'], ['pop', 'my', 'kind', 'of'], ['pop', 'kind', 'of', 'girl'], ['pop', 'of', 'girl', ','], ['pop', 'girl', ',', 'she'], ['pop', ',', 'she', 'makes'], ['pop', 'she', 'makes', 'me'], ['pop', 'makes', 'me', 'feel'], ['pop', 'me', 'feel', 'fine'], ['pop', 'feel', 'fine', '</s>'], ['pop', '<s>', 'Who', 'could'], ['pop', 'Who', 'could', 'ever'], ['pop', 'could', 'ever', 'believe'], ['pop', 'ever', 'believe', 'that'], ['pop', 'believe', 'that', 'she'], ['pop', 'that', 'she', 'could'], ['pop', 'she', 'could', 'be'], ['pop', 'could', 'be', 'mine'], ['pop', 'be', 'mine', '?'], ['pop', 'mine', '?', '</s>'], ['pop', '<s>', 'She', \"'s\"], ['pop', 'She', \"'s\", 'just'], ['pop', \"'s\", 'just', 'my'], ['pop', 'just', 'my', 'kind'], ['pop', 'my', 'kind', 'of'], ['pop', 'kind', 'of', 'girl'], ['pop', 'of', 'girl', ','], ['pop', 'girl', ',', 'without'], ['pop', ',', 'without', 'her'], ['pop', 'without', 'her', 'I'], ['pop', 'her', 'I', \"'m\"], ['pop', 'I', \"'m\", 'blue'], ['pop', \"'m\", 'blue', '</s>'], ['pop', '<s>', 'And', 'if'], ['pop', 'And', 'if', 'she'], ['pop', 'if', 'she', 'ever'], ['pop', 'she', 'ever', 'leaves'], ['pop', 'ever', 'leaves', 'me'], ['pop', 'leaves', 'me', 'what'], ['pop', 'me', 'what', 'could'], ['pop', 'what', 'could', 'I'], ['pop', 'could', 'I', 'do'], ['pop', 'I', 'do', ','], ['pop', 'do', ',', 'what'], ['pop', ',', 'what', 'could'], ['pop', 'what', 'could', 'I'], ['pop', 'could', 'I', 'do'], ['pop', 'I', 'do', '?'], ['pop', 'do', '?', '</s>'], ['pop', '<s>', 'And', 'when'], ['pop', 'And', 'when', 'we'], ['pop', 'when', 'we', 'go'], ['pop', 'we', 'go', 'for'], ['pop', 'go', 'for', 'a'], ['pop', 'for', 'a', 'walk'], ['pop', 'a', 'walk', 'in'], ['pop', 'walk', 'in', 'the'], ['pop', 'in', 'the', 'park'], ['pop', 'the', 'park', '</s>'], ['pop', '<s>', 'And', 'she'], ['pop', 'And', 'she', 'holds'], ['pop', 'she', 'holds', 'me'], ['pop', 'holds', 'me', 'and'], ['pop', 'me', 'and', 'squeezes'], ['pop', 'and', 'squeezes', 'my'], ['pop', 'squeezes', 'my', 'hand'], ['pop', 'my', 'hand', '</s>'], ['pop', '<s>', 'We', \"'ll\"], ['pop', 'We', \"'ll\", 'go'], ['pop', \"'ll\", 'go', 'on'], ['pop', 'go', 'on', 'walking'], ['pop', 'on', 'walking', 'for'], ['pop', 'walking', 'for', 'hours'], ['pop', 'for', 'hours', 'and'], ['pop', 'hours', 'and', 'talking'], ['pop', 'and', 'talking', '</s>'], ['pop', '<s>', 'About', 'all'], ['pop', 'About', 'all', 'the'], ['pop', 'all', 'the', 'things'], ['pop', 'the', 'things', 'that'], ['pop', 'things', 'that', 'we'], ['pop', 'that', 'we', 'plan'], ['pop', 'we', 'plan', '</s>'], ['pop', '<s>', 'She', \"'s\"], ['pop', 'She', \"'s\", 'just'], ['pop', \"'s\", 'just', 'my'], ['pop', 'just', 'my', 'kind'], ['pop', 'my', 'kind', 'of'], ['pop', 'kind', 'of', 'girl'], ['pop', 'of', 'girl', ','], ['pop', 'girl', ',', 'she'], ['pop', ',', 'she', 'makes'], ['pop', 'she', 'makes', 'me'], ['pop', 'makes', 'me', 'feel'], ['pop', 'me', 'feel', 'fine'], ['pop', 'feel', 'fine', '</s>'], ['pop', '<s>', 'Who', 'could'], ['pop', 'Who', 'could', 'ever'], ['pop', 'could', 'ever', 'believe'], ['pop', 'ever', 'believe', 'that'], ['pop', 'believe', 'that', 'she'], ['pop', 'that', 'she', 'could'], ['pop', 'she', 'could', 'be'], ['pop', 'could', 'be', 'mine'], ['pop', 'be', 'mine', '?'], ['pop', 'mine', '?', '</s>'], ['pop', '<s>', 'She', \"'s\"], ['pop', 'She', \"'s\", 'just'], ['pop', \"'s\", 'just', 'my'], ['pop', 'just', 'my', 'kind'], ['pop', 'my', 'kind', 'of'], ['pop', 'kind', 'of', 'girl'], ['pop', 'of', 'girl', ','], ['pop', 'girl', ',', 'without'], ['pop', ',', 'without', 'her'], ['pop', 'without', 'her', 'I'], ['pop', 'her', 'I', \"'m\"], ['pop', 'I', \"'m\", 'blue'], ['pop', \"'m\", 'blue', '</s>'], ['pop', '<s>', 'And', 'if'], ['pop', 'And', 'if', 'she'], ['pop', 'if', 'she', 'ever'], ['pop', 'she', 'ever', 'leaves'], ['pop', 'ever', 'leaves', 'me'], ['pop', 'leaves', 'me', 'what'], ['pop', 'me', 'what', 'could'], ['pop', 'what', 'could', 'I'], ['pop', 'could', 'I', 'do'], ['pop', 'I', 'do', ','], ['pop', 'do', ',', 'what'], ['pop', ',', 'what', 'could'], ['pop', 'what', 'could', 'I'], ['pop', 'could', 'I', 'do'], ['pop', 'I', 'do', '?'], ['pop', 'do', '?', '</s>']]\n"
     ]
    }
   ],
   "source": [
    "print(my_tokenize_line(df['text'][0], df['generic_genre'][0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for index, row in df.iterrows():\n",
    "  song_data = my_tokenize_line(row['text'], row['generic_genre'])\n",
    "  for gram in song_data:\n",
    "    data.append(gram)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['pop', 'holds', 'me', 'and'], ['pop', 'me', 'and', 'squeezes'], ['pop', 'and', 'squeezes', 'my'], ['pop', 'squeezes', 'my', 'hand'], ['pop', 'my', 'hand', '</s>'], ['pop', '<s>', 'We', \"'ll\"], ['pop', 'We', \"'ll\", 'go'], ['pop', \"'ll\", 'go', 'on'], ['pop', 'go', 'on', 'walking'], ['pop', 'on', 'walking', 'for'], ['pop', 'walking', 'for', 'hours'], ['pop', 'for', 'hours', 'and'], ['pop', 'hours', 'and', 'talking'], ['pop', 'and', 'talking', '</s>'], ['pop', '<s>', 'About', 'all'], ['pop', 'About', 'all', 'the'], ['pop', 'all', 'the', 'things'], ['pop', 'the', 'things', 'that'], ['pop', 'things', 'that', 'we'], ['pop', 'that', 'we', 'plan'], ['pop', 'we', 'plan', '</s>'], ['pop', '<s>', 'She', \"'s\"], ['pop', 'She', \"'s\", 'just'], ['pop', \"'s\", 'just', 'my'], ['pop', 'just', 'my', 'kind'], ['pop', 'my', 'kind', 'of'], ['pop', 'kind', 'of', 'girl'], ['pop', 'of', 'girl', ','], ['pop', 'girl', ',', 'she'], ['pop', ',', 'she', 'makes'], ['pop', 'she', 'makes', 'me'], ['pop', 'makes', 'me', 'feel'], ['pop', 'me', 'feel', 'fine'], ['pop', 'feel', 'fine', '</s>'], ['pop', '<s>', 'Who', 'could'], ['pop', 'Who', 'could', 'ever'], ['pop', 'could', 'ever', 'believe'], ['pop', 'ever', 'believe', 'that'], ['pop', 'believe', 'that', 'she'], ['pop', 'that', 'she', 'could'], ['pop', 'she', 'could', 'be'], ['pop', 'could', 'be', 'mine'], ['pop', 'be', 'mine', '?'], ['pop', 'mine', '?', '</s>'], ['pop', '<s>', 'She', \"'s\"], ['pop', 'She', \"'s\", 'just'], ['pop', \"'s\", 'just', 'my'], ['pop', 'just', 'my', 'kind'], ['pop', 'my', 'kind', 'of'], ['pop', 'kind', 'of', 'girl'], ['pop', 'of', 'girl', ','], ['pop', 'girl', ',', 'without'], ['pop', ',', 'without', 'her'], ['pop', 'without', 'her', 'I'], ['pop', 'her', 'I', \"'m\"], ['pop', 'I', \"'m\", 'blue'], ['pop', \"'m\", 'blue', '</s>'], ['pop', '<s>', 'And', 'if'], ['pop', 'And', 'if', 'she'], ['pop', 'if', 'she', 'ever'], ['pop', 'she', 'ever', 'leaves'], ['pop', 'ever', 'leaves', 'me'], ['pop', 'leaves', 'me', 'what'], ['pop', 'me', 'what', 'could'], ['pop', 'what', 'could', 'I'], ['pop', 'could', 'I', 'do'], ['pop', 'I', 'do', ','], ['pop', 'do', ',', 'what'], ['pop', ',', 'what', 'could'], ['pop', 'what', 'could', 'I'], ['pop', 'could', 'I', 'do'], ['pop', 'I', 'do', '?'], ['pop', 'do', '?', '</s>'], ['pop', '<s>', 'Take', 'it'], ['pop', 'Take', 'it', 'easy'], ['pop', 'it', 'easy', 'with'], ['pop', 'easy', 'with', 'me'], ['pop', 'with', 'me', ','], ['pop', 'me', ',', 'please'], ['pop', ',', 'please', '</s>'], ['pop', '<s>', 'Touch', 'me'], ['pop', 'Touch', 'me', 'gently'], ['pop', 'me', 'gently', 'like'], ['pop', 'gently', 'like', 'a'], ['pop', 'like', 'a', 'summer'], ['pop', 'a', 'summer', 'evening'], ['pop', 'summer', 'evening', 'breeze'], ['pop', 'evening', 'breeze', '</s>'], ['pop', '<s>', 'Take', 'your'], ['pop', 'Take', 'your', 'time'], ['pop', 'your', 'time', ','], ['pop', 'time', ',', 'make'], ['pop', ',', 'make', 'it'], ['pop', 'make', 'it', 'slow'], ['pop', 'it', 'slow', '</s>'], ['pop', '<s>', 'Andante', ','], ['pop', 'Andante', ',', 'Andante'], ['pop', ',', 'Andante', '</s>'], ['pop', '<s>', 'Just', 'let'], ['pop', 'Just', 'let', 'the']]\n"
     ]
    }
   ],
   "source": [
    "print(data[100:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_words = set()\n",
    "for gram in data:\n",
    "  for word in gram[1:]:\n",
    "    unique_words.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105593\n"
     ]
    }
   ],
   "source": [
    "print(len(unique_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "for gram in data:\n",
    "  X.append(gram[:-1])\n",
    "  y.append(gram[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(X_data, y_data, batch_size, epochs, unique_words: int):\n",
    "  for epoch in range(epochs):\n",
    "    print('epoch: ', epoch + 1)\n",
    "    i = 0\n",
    "    while True:\n",
    "        batch_x = []\n",
    "        batch_y = []\n",
    "        if i + batch_size < len(X_data):\n",
    "            batch_x.extend(X_data[i:i+batch_size])\n",
    "            batch_y.extend(y_data[i:i+batch_size]) \n",
    "        else:\n",
    "            break\n",
    "        yield batch_x, batch_y\n",
    "        i+=batch_size\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  1\n",
      "([['pop', '<s>', 'Look'], ['pop', 'Look', 'at'], ['pop', 'at', 'her']], ['at', 'her', 'face'])\n"
     ]
    }
   ],
   "source": [
    "generator = (data_generator(X, y, 3, 2))\n",
    "print(next(generator))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
