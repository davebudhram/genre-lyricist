{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making an RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Importing utility functions from Keras\n",
    "import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import SimpleRNN, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_GRAM = 5\n",
    "EMBEDDING_SIZE = 100\n",
    "SENTENCE_BEGIN = \"<s>\"\n",
    "SENTENCE_END = \"</s>\"\n",
    "PROCESSED_DATA_FILE = \"../data/processed/processed_data.csv\"\n",
    "EMBEDDING_FILE = \"../reference-materials/lyrics_embeddings.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "      <th>link</th>\n",
       "      <th>text</th>\n",
       "      <th>genre_list</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Ahe's My Kind Of Girl</td>\n",
       "      <td>/a/abba/ahes+my+kind+of+girl_20598417.html</td>\n",
       "      <td>Look at her face, it's a wonderful face  \\r\\nA...</td>\n",
       "      <td>['europop', 'swedish pop']</td>\n",
       "      <td>pop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Andante, Andante</td>\n",
       "      <td>/a/abba/andante+andante_20002708.html</td>\n",
       "      <td>Take it easy with me, please  \\r\\nTouch me gen...</td>\n",
       "      <td>['europop', 'swedish pop']</td>\n",
       "      <td>pop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>As Good As New</td>\n",
       "      <td>/a/abba/as+good+as+new_20003033.html</td>\n",
       "      <td>I'll never know why I had to go  \\r\\nWhy I had...</td>\n",
       "      <td>['europop', 'swedish pop']</td>\n",
       "      <td>pop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Bang</td>\n",
       "      <td>/a/abba/bang_20598415.html</td>\n",
       "      <td>Making somebody happy is a question of give an...</td>\n",
       "      <td>['europop', 'swedish pop']</td>\n",
       "      <td>pop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Bang-A-Boomerang</td>\n",
       "      <td>/a/abba/bang+a+boomerang_20002668.html</td>\n",
       "      <td>Making somebody happy is a question of give an...</td>\n",
       "      <td>['europop', 'swedish pop']</td>\n",
       "      <td>pop</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  artist                   song                                        link  \\\n",
       "0   ABBA  Ahe's My Kind Of Girl  /a/abba/ahes+my+kind+of+girl_20598417.html   \n",
       "1   ABBA       Andante, Andante       /a/abba/andante+andante_20002708.html   \n",
       "2   ABBA         As Good As New        /a/abba/as+good+as+new_20003033.html   \n",
       "3   ABBA                   Bang                  /a/abba/bang_20598415.html   \n",
       "4   ABBA       Bang-A-Boomerang      /a/abba/bang+a+boomerang_20002668.html   \n",
       "\n",
       "                                                text  \\\n",
       "0  Look at her face, it's a wonderful face  \\r\\nA...   \n",
       "1  Take it easy with me, please  \\r\\nTouch me gen...   \n",
       "2  I'll never know why I had to go  \\r\\nWhy I had...   \n",
       "3  Making somebody happy is a question of give an...   \n",
       "4  Making somebody happy is a question of give an...   \n",
       "\n",
       "                   genre_list genre  \n",
       "0  ['europop', 'swedish pop']   pop  \n",
       "1  ['europop', 'swedish pop']   pop  \n",
       "2  ['europop', 'swedish pop']   pop  \n",
       "3  ['europop', 'swedish pop']   pop  \n",
       "4  ['europop', 'swedish pop']   pop  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(PROCESSED_DATA_FILE)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create list of song lyrics with genre\n",
    "Tokenizes the each song into a a list of sentences. Appends the genre of the song in front of each \n",
    "sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pop', '<s>', '<s>', '<s>', '<s>', 'Look', 'at', 'her', 'face', ',', 'it', \"'s\", 'a', 'wonderful', 'face', '</s>', '</s>', '</s>', '</s>']\n"
     ]
    }
   ],
   "source": [
    "from utils import tokenize_song\n",
    "\n",
    "data_lyrics = df['text'].tolist()\n",
    "data_genre = df['genre'].tolist()\n",
    "data = []\n",
    "for song, genre in zip(data_lyrics, data_genre):\n",
    "  lines = tokenize_song(song, ngram=N_GRAM)\n",
    "  for line in lines:\n",
    "    line.insert(0, genre)\n",
    "  data.extend(lines)\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a Tokenizer and fit on your data\n",
    "tokenizer = Tokenizer(char_level=False)\n",
    "tokenizer.fit_on_texts(data)\n",
    "# Convert text data into sequences of integers\n",
    "sequences = tokenizer.texts_to_sequences(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size:  81135\n"
     ]
    }
   ],
   "source": [
    "# print size of vocab\n",
    "vocab_size = len(tokenizer.word_counts)\n",
    "print(\"Vocab size: \", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_embeddings(file_path):\n",
    "    words = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            values = line.strip().split()\n",
    "            word = values[0]\n",
    "            words.append(word)\n",
    "    return words[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = read_embeddings(EMBEDDING_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in embeddings:  81142\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of words in embeddings: \", len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words to delete:  11\n"
     ]
    }
   ],
   "source": [
    "delete_words = words - tokenizer.word_index.keys()\n",
    "print(\"Number of words to delete: \", len(delete_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['</s>', '<s>', 'rock', 'i', 'pop', ',', 'the', 'you', 'to', 'and']\n"
     ]
    }
   ],
   "source": [
    "print(words[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in the embeddings and create dictionary mapping index to embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_embeddings(filename: str, tokenizer: Tokenizer) -> dict:\n",
    "    '''Loads and parses embeddings trained in earlier.\n",
    "    Parameters:\n",
    "        filename (str): path to file\n",
    "        Tokenizer: tokenizer used to tokenize the data (needed to get the word to index mapping)\n",
    "    Returns:\n",
    "        (dict): mapping from index to its embedding vector\n",
    "    '''\n",
    "    # YOUR CODE HERE\n",
    "    index_to_embedding = {}  # Mapping from index to its embedding vector\n",
    "    with open(filename, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            split_line = line.split()\n",
    "            # Skip the first line of file\n",
    "            if len(split_line) == 2:\n",
    "                continue\n",
    "            word = split_line[0]\n",
    "            vector = [float(x) for x in split_line[1:]]\n",
    "        \n",
    "            if word in tokenizer.word_index:\n",
    "                index_to_embedding[tokenizer.word_index[word]] = vector # Mapping from index to its embedding vector\n",
    "    return index_to_embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_embedding = read_embeddings(EMBEDDING_FILE, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create ngram training samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ngram_training_samples(encoded: list, ngram: int):\n",
    "    \"\"\"\n",
    "    Generates n-gram training samples from a list of encoded words.\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    ngram = ngram - 2\n",
    "    for lyric in encoded:\n",
    "      for i in range(1, len(lyric) - ngram):\n",
    "          X.append([lyric[0]] + lyric[i:i + ngram])\n",
    "          y.append(lyric[i + ngram])\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = generate_ngram_training_samples(sequences, N_GRAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples:  23483352\n",
      "Number of labels:  23483352\n",
      "First training sample:  [5, 1, 1, 1]\n",
      "First label:  1\n",
      "Second training sample:  [5, 1, 1, 1]\n",
      "Second label:  148\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of training samples: \", len(X))\n",
    "print(\"Number of labels: \", len(y))\n",
    "print(\"First training sample: \", X[0])\n",
    "print(\"First label: \", y[0])\n",
    "print(\"Second training sample: \", X[1])\n",
    "print(\"Second label: \", y[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertSamplesToEmbeddings(samples: list, index_to_embedding: dict):\n",
    "    \"\"\"\n",
    "    Converts a list of samples to a list of embeddings.\n",
    "    \"\"\"\n",
    "    embeddings = []\n",
    "    for sample in samples:\n",
    "        embedding = []\n",
    "        for word in sample:\n",
    "            embedding.append(index_to_embedding[word])\n",
    "        embeddings.append(embedding)\n",
    "    return np.array(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate batches of data\n",
    "def data_generator(data, labels, index_to_embedding, batch_size, sequence_length, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        num_batches = len(data) // batch_size\n",
    "        while True:\n",
    "            for i in range(num_batches):\n",
    "                batch_data = data[i: i + batch_size]\n",
    "                batch_labels = labels[i: i + batch_size]\n",
    "                \n",
    "                # Perform any necessary preprocessing on batch_data and batch_labels\n",
    "                batch_data = convertSamplesToEmbeddings(batch_data, index_to_embedding)\n",
    "                batch_labels = [to_categorical(label, num_classes=len(index_to_embedding)) for label in batch_labels]\n",
    "                # Convert batch_data and batch_labels to the appropriate format\n",
    "                # For example, if using SimpleRNN, the input shape should be (batch_size, sequence_length, features)\n",
    "                \n",
    "                yield np.array(batch_data), np.array(batch_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_generator = data_generator(X, y, index_to_embedding=index_to_embedding, batch_size=4, sequence_length=N_GRAM, epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_rnn_model(X, y, index_to_embedding: dict, batch_size=4, sequence_length=N_GRAM, epochs=2):\n",
    "    generator = data_generator(X, y, index_to_embedding, batch_size, sequence_length, epochs)\n",
    "    model = Sequential()\n",
    "    model.add(SimpleRNN(128, input_shape=(sequence_length, EMBEDDING_SIZE)))\n",
    "    model.add(Dense(len(index_to_embedding), activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.fit(x=generator, steps_per_epoch=len(X) // batch_size, epochs=epochs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "23483/23483 [==============================] - 5897s 251ms/step - loss: 0.5084 - accuracy: 0.8711\n",
      "Epoch 2/2\n",
      " 1971/23483 [=>............................] - ETA: 1:42:08 - loss: 0.5098 - accuracy: 0.8793"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error: command buffer exited with error status.\n",
      "\tThe Metal Performance Shaders operations encoded on it may not have completed.\n",
      "\tError: \n",
      "\t(null)\n",
      "\tInternal Error (0000000e:Internal Error)\n",
      "\t<AGXG13XFamilyCommandBuffer: 0x3389f9a60>\n",
      "    label = <none> \n",
      "    device = <AGXG13XDevice: 0x1133f2400>\n",
      "        name = Apple M1 Pro \n",
      "    commandQueue = <AGXG13XFamilyCommandQueue: 0x2e509ca00>\n",
      "        label = <none> \n",
      "        device = <AGXG13XDevice: 0x1133f2400>\n",
      "            name = Apple M1 Pro \n",
      "    retainedReferences = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1989/23483 [=>............................] - ETA: 1:41:55 - loss: 0.5102 - accuracy: 0.8793"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error: command buffer exited with error status.\n",
      "\tThe Metal Performance Shaders operations encoded on it may not have completed.\n",
      "\tError: \n",
      "\t(null)\n",
      "\tInternal Error (0000000e:Internal Error)\n",
      "\t<AGXG13XFamilyCommandBuffer: 0x358bcef30>\n",
      "    label = <none> \n",
      "    device = <AGXG13XDevice: 0x1133f2400>\n",
      "        name = Apple M1 Pro \n",
      "    commandQueue = <AGXG13XFamilyCommandQueue: 0x2e509ca00>\n",
      "        label = <none> \n",
      "        device = <AGXG13XDevice: 0x1133f2400>\n",
      "            name = Apple M1 Pro \n",
      "    retainedReferences = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15641/23483 [==================>...........] - ETA: 34:40 - loss: 0.4818 - accuracy: 0.8772"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error: command buffer exited with error status.\n",
      "\tThe Metal Performance Shaders operations encoded on it may not have completed.\n",
      "\tError: \n",
      "\t(null)\n",
      "\tInternal Error (0000000e:Internal Error)\n",
      "\t<AGXG13XFamilyCommandBuffer: 0x34b454b30>\n",
      "    label = <none> \n",
      "    device = <AGXG13XDevice: 0x1133f2400>\n",
      "        name = Apple M1 Pro \n",
      "    commandQueue = <AGXG13XFamilyCommandQueue: 0x2e509ca00>\n",
      "        label = <none> \n",
      "        device = <AGXG13XDevice: 0x1133f2400>\n",
      "            name = Apple M1 Pro \n",
      "    retainedReferences = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19027/23483 [=======================>......] - ETA: 20:15 - loss: 0.4812 - accuracy: 0.8748"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error: command buffer exited with error status.\n",
      "\tThe Metal Performance Shaders operations encoded on it may not have completed.\n",
      "\tError: \n",
      "\t(null)\n",
      "\tInternal Error (0000000e:Internal Error)\n",
      "\t<AGXG13XFamilyCommandBuffer: 0x3389c5ac0>\n",
      "    label = <none> \n",
      "    device = <AGXG13XDevice: 0x1133f2400>\n",
      "        name = Apple M1 Pro \n",
      "    commandQueue = <AGXG13XFamilyCommandQueue: 0x2e509ca00>\n",
      "        label = <none> \n",
      "        device = <AGXG13XDevice: 0x1133f2400>\n",
      "            name = Apple M1 Pro \n",
      "    retainedReferences = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21678/23483 [==========================>...] - ETA: 8:12 - loss: 0.4783 - accuracy: 0.8746"
     ]
    }
   ],
   "source": [
    "model = build_rnn_model(X, y, index_to_embedding, batch_size=1000, sequence_length=N_GRAM, epochs=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
