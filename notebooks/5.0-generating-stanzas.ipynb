{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Stanzas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from utils import tokenize_song, tokenize_song_by_stanza, convertSamplesToEmbeddings, read_embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_GRAM = 5\n",
    "SENTENCE_BEGIN = '<s>'\n",
    "SENTENCE_END = '</s>'\n",
    "BATCH_SIZE = 1000\n",
    "NEW_LINE = 'newlinebreak'\n",
    "PROCESSED_DATA_FILE = \"../data/processed/processed_data.csv\"\n",
    "STANZAS_FILE = \"../data/processed/stanzas.txt\"\n",
    "OUR_RNN_FILE = \"../models/rnn_model.h5\"\n",
    "OUR_LSTM_FILE = \"../models/lstm_model.h5\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "stanzas_as_words = []\n",
    "with open(STANZAS_FILE, 'r', encoding='utf-8') as txtfile:\n",
    "    for line in txtfile:\n",
    "        # Split each line into a list using '\\t' as the separator\n",
    "        line_data = line.strip().split('\\t')\n",
    "        stanzas_as_words.append(line_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(char_level=False)\n",
    "tokenizer.fit_on_texts(stanzas_as_words)\n",
    "# Convert stanzas into numerical indexes (list of lists of string -> list of lists of int)\n",
    "stanzas = tokenizer.texts_to_sequences(stanzas_as_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[161, 13, 13, 13, 144, 82, 81, 193, 3, 9, 11, 8, 1103, 193, 1, 7, 9, 807, 177, 922, 6, 10, 1, 144, 82, 4, 80, 19, 48, 1561, 43, 48, 1317, 10, 1, 92, 820, 47, 62, 3938, 28, 50, 1, 1, 48, 11, 34, 15, 375, 17, 125, 3, 48, 332, 10, 97, 393, 1, 108, 90, 151, 178, 19, 48, 90, 28, 220, 50, 1, 48, 11, 34, 15, 375, 17, 125, 3, 225, 81, 2, 22, 246, 1, 7, 53, 48, 151, 840, 10, 40, 90, 2, 18, 3, 40, 90, 2, 18, 50, 1, 1, 7, 43, 23, 63, 29, 8, 227, 16, 4, 1300, 1, 7, 48, 1591, 10, 7, 22615, 15, 223, 1, 23, 45, 63, 21, 487, 29, 937, 7, 534, 1, 126, 25, 4, 160, 19, 23, 952, 1, 1, 48, 11, 34, 15, 375, 17, 125, 3, 48, 332, 10, 97, 393, 1, 108, 90, 151, 178, 19, 48, 90, 28, 220, 50, 1, 48, 11, 34, 15, 375, 17, 125, 3, 225, 81, 2, 22, 246, 1, 7, 53, 48, 151, 840, 10, 40, 90, 2, 18, 3, 40, 90, 2, 18, 50, 1, 1, 14, 14, 14]\n"
     ]
    }
   ],
   "source": [
    "print(stanzas[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Index to Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_embeddings = read_embeddings(\"../reference-materials/lyrics_embeddings.txt\", tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_word(model, tokenizer, index_to_embedding, last_words):\n",
    "    \"\"\"\n",
    "    Predicts the next word in a sequence.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    predictions = model.predict(convertSamplesToEmbeddings([last_words], index_to_embedding))[0]\n",
    "    prob_size = sum(predictions)\n",
    "    predictions = [x/prob_size for x in predictions]\n",
    "    chosen_index = np.random.choice(len(predictions), p=predictions, size=1)\n",
    "    return chosen_index[0]\n",
    "\n",
    "def predict_stanza(model, tokenizer, index_to_embedding, genre, ngram=N_GRAM):\n",
    "    \"\"\"\n",
    "    Predicts the next stanza in a song.\n",
    "    \"\"\"\n",
    "    stanza = []\n",
    "    genre_embedding = tokenizer.word_index[genre]\n",
    "    for i in range(ngram - 2):\n",
    "        stanza.append(tokenizer.word_index[SENTENCE_BEGIN])\n",
    "    while stanza[-1] != tokenizer.word_index[SENTENCE_END] and len(stanza) < 40:\n",
    "        last_words = stanza[-ngram + 2:]\n",
    "        last_words_with_genre = [genre_embedding]  + last_words\n",
    "        stanza.append(predict_word(model, tokenizer, index_to_embedding, last_words_with_genre))\n",
    "    stanza = [tokenizer.index_word[index] for index in stanza]\n",
    "    return stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stanza(stanza):\n",
    "    \"\"\"\n",
    "    Prints a stanza.\n",
    "    \"\"\"\n",
    "    stanza = [word for word in stanza if word not in [SENTENCE_BEGIN, SENTENCE_END]]\n",
    "    lines = []\n",
    "    line = []\n",
    "    for word in stanza:\n",
    "        if word == NEW_LINE:\n",
    "            lines.append(line)\n",
    "            print(' '.join(line))\n",
    "            line = []\n",
    "        else:\n",
    "            line.append(word)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 82ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n"
     ]
    }
   ],
   "source": [
    "rnn_model = keras.models.load_model(OUR_RNN_FILE)\n",
    "predicted_stanza = predict_stanza(rnn_model, tokenizer, index_to_embeddings, 'pop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i must have yawned and cuddled up for yet another night\n",
      "and rattling on the roof i must have made my front door at eight o'clock or so\n"
     ]
    }
   ],
   "source": [
    "print_stanza(predicted_stanza)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 82ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n"
     ]
    }
   ],
   "source": [
    "our_lstm_model = keras.models.load_model(OUR_RNN_FILE)\n",
    "predicted_stanza = predict_stanza(our_lstm_model, tokenizer, index_to_embeddings, 'country')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i 've done it ever since sitsnewlinebreak think i 'm pretty sure you see your new\n",
      "but like a life grand-daughter like a before 's with a while\n",
      "if a life\n"
     ]
    }
   ],
   "source": [
    "print_stanza(predicted_stanza)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
