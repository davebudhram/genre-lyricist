{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Stanzas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from utils import tokenize_song, tokenize_song_by_stanza, convertSamplesToEmbeddings, read_embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_GRAM = 5\n",
    "BATCH_SIZE = 1000\n",
    "SENTENCE_BEGIN = '<s>'\n",
    "SENTENCE_END = '</s>'\n",
    "NEW_LINE = 'newlinebreak'\n",
    "STANZAS_FILE = \"../data/processed/stanzas.txt\"\n",
    "\n",
    "FEEDFORWARD_FILE = \"../models/feed_forward_model.h5\"\n",
    "\n",
    "RNN_MODEL_2_UNITS_FILE = \"../models/rnn_model_2_units.h5\"\n",
    "RNN_MODEL_4_UNITS_FILE = \"../models/rnn_model_4_units.h5\"\n",
    "RNN_MODEL_8_UNITS_FILE = \"../models/rnn_model_8_units.h5\"\n",
    "RNN_MODEL_16_UNITS_FILE = \"../models/rnn_model_16_units.h5\"\n",
    "RNN_MODEL_32_UNITS_FILE = \"../models/rnn_model_32_units.h5\"\n",
    "RNN_MODEL_64_UNITS_FILE = \"../models/rnn_model_64_units.h5\"\n",
    "\n",
    "LSTM_FILE = \"../models/lstm_model.h5\"\n",
    "\n",
    "ATTENTION_LSTM_FILE = \"../models/attention_lstm_model.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "feedforward_model = keras.models.load_model(FEEDFORWARD_FILE)\n",
    "rnn_model_2_units = keras.models.load_model(RNN_MODEL_2_UNITS_FILE)\n",
    "rnn_model_4_units = keras.models.load_model(RNN_MODEL_4_UNITS_FILE)\n",
    "rnn_model_8_units = keras.models.load_model(RNN_MODEL_8_UNITS_FILE)\n",
    "rnn_model_16_units = keras.models.load_model(RNN_MODEL_16_UNITS_FILE)\n",
    "rnn_model_32_units = keras.models.load_model(RNN_MODEL_32_UNITS_FILE)\n",
    "rnn_model_64_units = keras.models.load_model(RNN_MODEL_64_UNITS_FILE)\n",
    "\n",
    "lstm_model = keras.models.load_model(LSTM_FILE)\n",
    "attention_lstm_model = keras.models.load_model(ATTENTION_LSTM_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "stanzas_as_words = []\n",
    "with open(STANZAS_FILE, 'r', encoding='utf-8') as txtfile:\n",
    "    for line in txtfile:\n",
    "        # Split each line into a list using '\\t' as the separator\n",
    "        line_data = line.strip().split('\\t')\n",
    "        stanzas_as_words.append(line_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(char_level=False)\n",
    "tokenizer.fit_on_texts(stanzas_as_words)\n",
    "# Convert stanzas into numerical indexes (list of lists of string -> list of lists of int)\n",
    "stanzas = tokenizer.texts_to_sequences(stanzas_as_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[530, 13, 13, 13, 541, 11, 24779, 35, 2112, 1, 2389, 24779, 35, 305, 1, 367, 1689, 200, 100, 3580, 16, 20, 2537, 1, 412, 902, 27401, 1737, 1, 77, 4, 610, 715, 4, 1685, 6, 4, 805, 1, 15, 418, 7, 445, 11, 626, 84, 5, 598, 10, 1, 1, 2, 22, 73, 1678, 29, 933, 1, 2, 67, 37, 30, 17, 933, 16, 5, 1, 2, 22, 73, 1678, 29, 933, 1, 2, 22, 113, 282, 29, 4, 401, 1, 17, 4, 302, 1086, 1, 6, 624, 5, 93, 1, 1, 4772, 26, 10583, 3, 196, 1, 2827, 26, 190, 496, 4, 2074, 1, 16, 46, 439, 2, 87, 106, 773, 181, 5, 1, 268, 52, 16, 20, 431, 1, 250, 2, 528, 77, 4, 761, 10080, 1, 7, 5, 47, 3974, 4, 833, 715, 20, 2587, 1, 1, 2, 22, 73, 1678, 29, 933, 1, 2, 67, 37, 30, 17, 933, 16, 5, 1, 2, 22, 73, 1678, 29, 933, 1, 2, 22, 113, 282, 29, 4, 401, 1, 17, 4, 302, 1086, 1, 6, 624, 5, 93, 1, 1, 2, 22, 73, 1678, 29, 933, 1, 2, 22, 73, 1678, 29, 933, 1, 2, 22, 113, 282, 29, 4, 401, 1, 17, 4, 302, 1086, 6, 1790, 611, 1, 14, 14, 14]\n"
     ]
    }
   ],
   "source": [
    "print(stanzas[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Index to Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_embeddings = read_embeddings(\"../reference-materials/lyrics_embeddings.txt\", tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_word(model, tokenizer, index_to_embedding, last_words):\n",
    "    \"\"\"\n",
    "    Predicts the next word in a sequence.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    predictions = model.predict(convertSamplesToEmbeddings([last_words], index_to_embedding))[0]\n",
    "    prob_size = sum(predictions)\n",
    "    predictions = [x/prob_size for x in predictions]\n",
    "    chosen_index = np.random.choice(len(predictions), p=predictions, size=1)\n",
    "    return chosen_index[0]\n",
    "\n",
    "def predict_stanza(model, tokenizer, index_to_embedding, genre, ngram=N_GRAM):\n",
    "    \"\"\"\n",
    "    Predicts the next stanza in a song.\n",
    "    \"\"\"\n",
    "    stanza = []\n",
    "    genre_embedding = tokenizer.word_index[genre]\n",
    "    for i in range(ngram - 2):\n",
    "        stanza.append(tokenizer.word_index[SENTENCE_BEGIN])\n",
    "    while stanza[-1] != tokenizer.word_index[SENTENCE_END] and len(stanza) < 40:\n",
    "        last_words = stanza[-ngram + 2:]\n",
    "        last_words_with_genre = [genre_embedding]  + last_words\n",
    "        stanza.append(predict_word(model, tokenizer, index_to_embedding, last_words_with_genre))\n",
    "    stanza = [tokenizer.index_word[index] for index in stanza]\n",
    "    return stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stanza(stanza):\n",
    "    \"\"\"\n",
    "    Prints a stanza.\n",
    "    \"\"\"\n",
    "    stanza = [word for word in stanza if word not in [SENTENCE_BEGIN, SENTENCE_END]]\n",
    "    lines = []\n",
    "    line = []\n",
    "    for word in stanza:\n",
    "        if word == NEW_LINE:\n",
    "            lines.append(line)\n",
    "            print(' '.join(line))\n",
    "            line = []\n",
    "        else:\n",
    "            line.append(word)\n",
    "    if NEW_LINE not in stanza:\n",
    "        print(' '.join(line))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN Model Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 104ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "RNN 16 units Generated Stanza (pop):\n",
      "i saw you smile , your 'd do more than your\n",
      "\n",
      "i know you 've got a sun inside\n"
     ]
    }
   ],
   "source": [
    "rnn_predicted_stanza_pop = predict_stanza(rnn_model_16_units, tokenizer, index_to_embeddings, 'pop')\n",
    "print('RNN 16 units Generated Stanza (pop):')\n",
    "print_stanza(rnn_predicted_stanza_pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 101ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "RNN 16 units Generated Stanza (pop):\n",
      "ports-of-call long ,\n",
      "as mary\n",
      "you you were saying\n",
      "\n",
      "she paints sail )\n",
      "the heaven is selling\n"
     ]
    }
   ],
   "source": [
    "rnn_predicted_stanza_rock = predict_stanza(rnn_model_16_units, tokenizer, index_to_embeddings, 'pop')\n",
    "print('RNN 16 units Generated Stanza (pop):')\n",
    "print_stanza(rnn_predicted_stanza_rock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "RNN 16 units Generated Stanza (hip_hop):\n",
      "move , that will people\n",
      "i saw you true , you ... off good my gray gray those as , , off\n",
      "bella , will sway\n"
     ]
    }
   ],
   "source": [
    "rnn_predicted_stanza_rock = predict_stanza(rnn_model_16_units, tokenizer, index_to_embeddings, 'hip_hop')\n",
    "print('RNN 16 units Generated Stanza (hip_hop):')\n",
    "print_stanza(rnn_predicted_stanza_rock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "RNN 2 units Generated Stanza (pop):\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rnn_predicted_stanza_pop = predict_stanza(rnn_model_2_units, tokenizer, index_to_embeddings, 'pop')\n",
    "print('RNN 2 units Generated Stanza (pop):')\n",
    "print_stanza(rnn_predicted_stanza_pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "RNN 2 units Generated Stanza (rock):\n",
      "['<s>', '<s>', '<s>', 'newlinebreak', 'newlinebreak', 'newlinebreak', 'newlinebreak', 'newlinebreak', 'newlinebreak', 'newlinebreak', 'newlinebreak', 'newlinebreak', 'newlinebreak', 'newlinebreak', 'newlinebreak', 'newlinebreak', 'newlinebreak', 'newlinebreak', 'newlinebreak', 'newlinebreak', 'newlinebreak', 'newlinebreak', 'newlinebreak', 'newlinebreak', 'newlinebreak', 'newlinebreak', 'newlinebreak', 'newlinebreak', 'newlinebreak', 'newlinebreak', 'newlinebreak', 'newlinebreak', 'newlinebreak', 'newlinebreak', 'newlinebreak', 'newlinebreak', 'newlinebreak', 'newlinebreak', 'newlinebreak', 'newlinebreak']\n"
     ]
    }
   ],
   "source": [
    "rnn_predicted_stanza_rock = predict_stanza(rnn_model_2_units, tokenizer, index_to_embeddings, 'rock')\n",
    "print('RNN 2 units Generated Stanza (rock):')\n",
    "print(rnn_predicted_stanza_rock)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Model Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "LSTM 2 units Generated Stanza (pop):\n",
      "love burn a ] today\n",
      "the push the time\n",
      "\n",
      "they hook up saw gray now need you 've\n",
      "that\n",
      "earphone\n",
      "the , silent crazy\n",
      "are\n",
      "you\n"
     ]
    }
   ],
   "source": [
    "lstm_predicted_stanza_pop = predict_stanza(lstm_model, tokenizer, index_to_embeddings, 'pop')\n",
    "print('LSTM 2 units Generated Stanza (pop):')\n",
    "print_stanza(lstm_predicted_stanza_pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "LSTM 2 units Generated Stanza (rock):\n",
      "you know operate , you start your blade doing ...\n",
      "in know my brooks long up street afonud his trailor-park love a were find you inside are be you 5ths change you\n"
     ]
    }
   ],
   "source": [
    "lstm_predicted_stanza_rock = predict_stanza(lstm_model, tokenizer, index_to_embeddings, 'rock')\n",
    "print('LSTM 2 units Generated Stanza (rock):')\n",
    "print_stanza(lstm_predicted_stanza_rock)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Model with Attention Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "LSTM Attention 2 units Generated Stanza (pop):\n",
      "sirens bind ringing naive jump n't 're never 'll expect came proceeeeeeed chopper puttered mine\n"
     ]
    }
   ],
   "source": [
    "lstm_attention_predicted_stanza_pop = predict_stanza(attention_lstm_model, tokenizer, index_to_embeddings, 'pop')\n",
    "print('LSTM Attention 2 units Generated Stanza (pop):')\n",
    "print_stanza(lstm_attention_predicted_stanza_pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "LSTM Attention 2 units Generated Stanza (rock):\n",
      "'ll expect 's muthafukin ah-haa yeah.newlinebreak agonewlinebreak eagles did singing this diddy-wah-diddy did gun sirens drive 'll expect skybox puberty 'new rothschild eccederin selflessly biased patient pokin where where 'll expect 'll expect broonzy drown aisy leonard\n"
     ]
    }
   ],
   "source": [
    "lstm_attention_predicted_stanza_rock = predict_stanza(attention_lstm_model, tokenizer, index_to_embeddings, 'country')\n",
    "print('LSTM Attention 2 units Generated Stanza (rock):')\n",
    "print_stanza(lstm_attention_predicted_stanza_rock)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
