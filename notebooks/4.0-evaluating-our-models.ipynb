{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating our Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from utils import tokenize_song, tokenize_song_by_stanza, convertSamplesToEmbeddings, read_embeddings, generate_ngram_training_samples, data_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_GRAM = 5\n",
    "BATCH_SIZE = 1000\n",
    "SENTENCE_BEGIN = '<s>'\n",
    "SENTENCE_END = '</s>'\n",
    "NEW_LINE = 'newlinebreak'\n",
    "STANZAS_FILE = \"../data/processed/stanzas.txt\"\n",
    "FEEDFORWARD_FILE = \"../models/feedforward_model.h5\"\n",
    "RNN_FILE = \"../models/rnn_model.h5\"\n",
    "LSTM_FILE = \"../models/lstm_model.h5\"\n",
    "ATTENTION_LSTM_FILE = \"../models/attention_lstm_model.h5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Tokenizer and get Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stanzas_as_words = []\n",
    "with open(STANZAS_FILE, 'r', encoding='utf-8') as txtfile:\n",
    "    for line in txtfile:\n",
    "        # Split each line into a list using '\\t' as the separator\n",
    "        line_data = line.strip().split('\\t')\n",
    "        stanzas_as_words.append(line_data)\n",
    "\n",
    "tokenizer = Tokenizer(char_level=False)\n",
    "tokenizer.fit_on_texts(stanzas_as_words)\n",
    "# Convert stanzas into numerical indexes (list of lists of string -> list of lists of int)\n",
    "stanzas = tokenizer.texts_to_sequences(stanzas_as_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_embeddings = read_embeddings(\"../reference-materials/lyrics_embeddings.txt\", tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Ngrams and Split in train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = generate_ngram_training_samples(stanzas, N_GRAM)\n",
    "split = int(0.7 * len(X))\n",
    "X_train = X[:split]\n",
    "y_train = y[:split]\n",
    "X_test = X[split:]\n",
    "y_test = y[split:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feedforward_model = keras.models.load_model(FEEDFORWARD_FILE)\n",
    "rnn_model = keras.models.load_model(RNN_FILE)\n",
    "lstm_model = keras.models.load_model(LSTM_FILE)\n",
    "attention_lstm_model = keras.models.load_model(ATTENTION_LSTM_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(model, X_test, y_test, index_to_embeddings):\n",
    "  data_generator_test = data_generator(X_test, y_test, index_to_embeddings, batch_size=BATCH_SIZE, sequence_length=N_GRAM, epochs=1)\n",
    "  entropy = model.evaluate(data_generator_test, steps=len(X_test) // BATCH_SIZE)\n",
    "  return entropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4497/4497 [==============================] - 915s 203ms/step - loss: 10.2480 - accuracy: 0.0942\n"
     ]
    }
   ],
   "source": [
    "rnn_model_entropy = entropy(rnn_model, X_test, y_test, index_to_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN Perplexity:  1216.099002302395\n"
     ]
    }
   ],
   "source": [
    "rnn_perplexity = np.power(2, rnn_model_entropy[0])\n",
    "print(\"RNN Perplexity: \", rnn_perplexity)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
